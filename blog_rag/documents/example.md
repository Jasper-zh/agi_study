---
title: 大模型概述
date: 2024-08-01 18:15:54
tags: 总结文档
copyright: false
categories: 
- 记录文档
---

[toc]

## 提示词

**重点：**具体、丰富、少歧义；比如通过markdown的格式描述清晰



**典型结构：** 角色、指示、上下文、例子、输入、输出

比如：你是一个早餐点员工、你要根据你的早点菜单进行推荐以及报价、一些菜单信息以及之前的对话、对话例子、有什么面、按照自然语言输出



**进阶技巧：**

思维链；比如「Let’s think step by step」，原理是让大语言模型自己生成一些上下文信息，来辅助生成最终的结果

自洽性；多次生成结果，选择相似的多数



**提示词攻击：**

Prompt注入：用户输入的 prompt 改变了系统既定的设定，使其输出违背设计意图的内容。

预防手段：

* 提示词种注入分类器符合的就通过，继续回答，否则不通过。
* 输入中去注入提示



**内容审核API:**

可以通过调用 OpenAI 的 Moderation API 来识别用户发送的消息是否违法相关的法律法规，如果出现违规的内容，从而对它进行过滤。或者网易易盾





## 自然语言处理结构

语音识别ASR  -> 文本语义理解NLU -> 对话管理器（状态跟踪 -> 对话策略）-> 自然语言生成 -> 语音合成  

| **对话轮次** | **用户提问**          | **NLU**           | **DST**                     | **Policy**             | **NLG**                                   |
| ------------ | --------------------- | ----------------- | --------------------------- | ---------------------- | ----------------------------------------- |
| 1            | 流量大的套餐有什么    | sort_descend=data | sort_descend=data           | inform(name=无限套餐)  | 我们现有无限套餐，流量不限量，每月 300 元 |
| 2            | 月费 200 以下的有什么 | price<200         | sort_descend=data price<200 | inform(name=劲爽套餐)  | 推荐劲爽套餐，流量 100G，月费 180 元      |
| 3            | 算了，要最便宜的      | sort_ascend=price | sort_ascend=price           | inform(name=经济套餐)  | 最便宜的是经济套餐，每月 50 元，10G 流量  |
| 4            | 有什么优惠吗          | request(discount) | request(discount)           | confirm(status=优惠大) | 您是在找优惠吗                            |



## 函数回调

实际上只用提示词便可以完成，让大模型按照你规定触发时机以及响应的格式，来满足参数提取。然后再进行外部工具调用

但是只是靠提示词可能不太稳定，目前大部分的大模型已经提供了专门的函数回调功能，可能是通过训练加上更优的提示词，总之我们直接按照大模型提供的函数回调接口进行外部工具添加即可



## RAG基本搭建结构

搭建过程：

1. 文档加载，并按一定条件**切割**成片段
2. 将切割的文本片段灌入**检索引擎**
3. 封装**检索接口**
4. 构建**调用流程**：Query -> 检索 -> Prompt -> LLM -> 回复



但是在实际关于检索这一步，应该是意思相同或者相近的匹配，而不是字符串相等的搜索。因此在这个环节需要引入向量数据库，利用大语言模型去转向量，通过比较向量距离按相似度进行搜索。



**可优化的点：**

* 文本分割的颗粒度（需要决策前期分割粒度，以及后期前后覆盖度）
* 很多时候最贴切的答案可能不在第一个，可以进行一个检索后排序（使用另一个排序模型对查询和文档重新打分排序，相当于多个角度）



目前很多面向用户的大模型对话产品都提供了基于rag的功能，比如上传pdf



## 智能体API

在原来原生的大模型对外接口之外，进行了一次封装。封装出其他接口比如会话管理、外部工具配置、沙箱代码、内置RAG等等

比如OpenAI提供的Assistants API 异步调用并且可实时查看运行状态



## LLM应用开发SDK

所开发框架（SDK）都是降低开发以及维护成本，那么对于LLM的SDK提供了接入LLM 向量数据库 搜索引擎的抽象，封装了常用工具。

对于底层大模型的更换更加灵活，对于提示词的管理更加方便，保证了基础的线程安全，方便调试和测试

划重点：选对了框架，事半功倍；反之，事倍功半。

### Semantic kernel

semantic kernel是微软开发的一个面向大模型的SDK 目前提供的语言比较多,https://github.com/microsoft/semantic-kernel/tree/experimental-java

它希望让开发者调用不同的提示词取得大模型的反馈，就像调用函数一样简单。也就是一个提示词模板就是一个函数。让开发者和LLM解耦，在开发者的视角下并不会说我现在要调用大模型然后再组织提示词，而是我现在要干什么已经有个函数解决，我给这个函数传参就行了（这个函数背后只是一段提示词模板，参数用来填充模板里的占位词，然后调用了大模型处理了结构返回，对于开发者就像调用别的函数一样）

简单来说传统去用大模型，是开发者直接调用大模型，用来用去就是调用一个接口只是要准备不同的提示词。现在是多个接口和大模型没关系，是预先把常用的一些调用已经封装成一些函数了。开发者知道这个函数的输入输出是什么就OK了，甚至在它的格式和语法之下，你都不知道这个函数是代码的函数还是LLM函数，除非用功能点进去看里面的实现。

### langchain

同样也是一个SDK 迭代比较快，更关注接口变更。

统一了各种模型的调用接口，提供了输出解析器，LCEL表达式链式调用



总的来说Semantic kernel更多是想要定义一种传统代码和LLM进行混合开发的一种项目模型的方式，langchain就是在方方面面封装了很多实际的工具。目前SK的支持语言多一点，langchain主要是python，除此之外langchain各方面的支持要更多



## 大模型维护设施

除了上面的技术，维护一个生产的应用少不了监控各种指标

对大模型来说：

1. 各种指标监控与统计：访问记录、响应时长、Token 用量、计费等等
2. 调试 Prompt
3. 测试/验证系统的相关评估指标
4. 数据集管理（便于回归测试）
5. Prompt 版本管理（便于升级/回滚）

目前市面上可以使用的生产级的维护平台有三个：

1. 重点讲解 **LangFuse**: 开源 + SaaS（免费/付费），LangSmith 平替，可集成 LangChain 也可直接对接 OpenAI API；
2. 简单讲解 **LangSmith**: LangChain 的官方平台，SaaS 服务（免费/付费），非开源，企业版支持私有部署；
3. 简单讲解 **Prompt Flow**：微软开发，开源 + Azure AI 云服务，可集成 Semantic Kernel（但貌合神离）。

部署好或者用saas服务，然后在服务平台复制公钥、密钥、地址，填入客户端SDK的配置当中（私有部署记得改默认数据库密码）

Langfuse记录的对话以trace为一条记录，一次对话中间可能有多个交互都在trace中，每个步骤就是observation（其中又分为event、span、generation）

### 接入

使用方式如果接入原生openai（导入langfuse的openai它给原生封装了一层接口和原生一样），封装调用大模型作为函数，加上@observe注解进行配置,调用函数则会被记录到平台。可以通过langfuse_context在调用前添加一些本次trace的额外信息.

除了使用原生还支持langchain，使用langchain进行llm交互时，是利用langchain提供的回调参数通过传入langfuse提供的函数来进行记录，这样对于使用langchain来说并没有发生改变，等于无缝接入langfuse

### 数据标注&测试

在记录的trace当中，可以人工筛选trace里面的步骤到到数据集，包含Input和Expected output ，也可以通过代码进行外部导入数据

通过langfuse提供的库编写脚本代码，获取数据集循环每条数据的输入进行LLM交互得到结果再与每条数据的预期结果进行评价（编写评价函数比如简单的相等），执行脚本后，langfuse平台数据集则会出现一条run数据，可以查看准确率等指标。若效果不行，则继续优化提示词，再进行回归测试

### 提示词管理

langfuse提供了提示词版本管理的功能，通过langfuse的接口来获取指定名称的提示词，以及传参编译。通过langfuse来构建完整提示词，就不用在定义chain时再构建参数，一般不太使用



## Agent

通过用户的提出的一个需求，能够自行的分析问题，拆解问题，计划执行步骤。内部自动进行多次的交互包括LLM的交互包括外部工具的交互，反复多次。最终给到答案的行为叫做Agent.

比如openai的AutoGPT就是一种Agent的智能体




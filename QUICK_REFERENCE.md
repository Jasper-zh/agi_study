# ğŸš€ å¿«é€Ÿå‚è€ƒå¡ç‰‡

## ğŸ“ é¡¹ç›®æ–‡ä»¶è¯´æ˜

| æ–‡ä»¶ | è¯´æ˜ |
|------|------|
| `config.py` | **ç»Ÿä¸€é…ç½®ç®¡ç†**ï¼Œæ‰€æœ‰ä»£ç éƒ½ä»è¿™é‡Œå¯¼å…¥é…ç½® |
| `.env` | **ä½ çš„ç§æœ‰é…ç½®**ï¼ˆä¸æäº¤åˆ° Gitï¼‰ï¼Œå­˜æ”¾ API Key |
| `.env.example` | **é…ç½®æ¨¡æ¿**ï¼Œå¯ä»¥åˆ†äº«ç»™ä»–äºº |
| `requirements.txt` | **é¡¹ç›®ä¾èµ–åˆ—è¡¨** |
| `setup.sh` | **è‡ªåŠ¨åŒ–å®‰è£…è„šæœ¬** |
| `CONFIG_USAGE.md` | **è¯¦ç»†çš„é…ç½®ä½¿ç”¨æ–‡æ¡£** |
| `README.md` | **é¡¹ç›®è¯´æ˜å’Œå¿«é€Ÿå¼€å§‹** |

## âš¡ å¸¸ç”¨å‘½ä»¤

### ç¯å¢ƒç®¡ç†

```bash
# æ¿€æ´» venv ç¯å¢ƒ
source .venv/bin/activate

# æ¿€æ´» conda ç¯å¢ƒ
conda activate agi_study

# é€€å‡ºè™šæ‹Ÿç¯å¢ƒ
deactivate  # venv
conda deactivate  # conda
```

### ä¾èµ–ç®¡ç†

```bash
# å®‰è£…ä¾èµ–ï¼ˆä½¿ç”¨é•œåƒï¼‰
pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple/

# å®‰è£…å•ä¸ªåŒ…
pip install package-name

# æŸ¥çœ‹å·²å®‰è£…çš„åŒ…
pip list

# å¯¼å‡ºå½“å‰ç¯å¢ƒçš„ä¾èµ–
pip freeze > requirements.txt
```

### é…ç½®ç®¡ç†

```bash
# åˆ›å»ºé…ç½®æ–‡ä»¶
cp .env.example .env

# æµ‹è¯•é…ç½®
python config.py

# æŸ¥çœ‹å½“å‰é…ç½®ï¼ˆåœ¨ Python ä¸­ï¼‰
from config import settings
settings.print_config()
```

## ğŸ’¡ ä»£ç æ¨¡æ¿

### 1. OpenAI åŸºç¡€ä½¿ç”¨

```python
from config import settings
from openai import OpenAI

client = OpenAI(
    api_key=settings.OPENAI_API_KEY,
    base_url=settings.OPENAI_BASE_URL
)

response = client.chat.completions.create(
    model=settings.OPENAI_MODEL,
    messages=[
        {"role": "user", "content": "Hello!"}
    ]
)
print(response.choices[0].message.content)
```

### 2. LangChain ä½¿ç”¨

```python
from config import settings
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    model=settings.OPENAI_MODEL,
    api_key=settings.OPENAI_API_KEY,
    base_url=settings.OPENAI_BASE_URL,
    temperature=settings.OPENAI_TEMPERATURE
)

response = llm.invoke("Hello!")
print(response.content)
```

### 3. LangGraph Agent

```python
from config import settings
from langchain_openai import ChatOpenAI
from langgraph.prebuilt import create_react_agent
from langchain_core.tools import tool

@tool
def my_tool(query: str) -> str:
    """å·¥å…·æè¿°"""
    return "ç»“æœ"

llm = ChatOpenAI(
    model=settings.OPENAI_MODEL,
    api_key=settings.OPENAI_API_KEY
)

agent = create_react_agent(llm, [my_tool])
result = agent.invoke({"messages": [("user", "ä½ å¥½")]})
```

### 4. RAG åº”ç”¨

```python
from config import settings
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA

# Embedding
embeddings = OpenAIEmbeddings(
    api_key=settings.OPENAI_API_KEY,
    base_url=settings.OPENAI_BASE_URL
)

# å‘é‡å­˜å‚¨
vectorstore = FAISS.from_texts(
    texts=["æ–‡æœ¬1", "æ–‡æœ¬2"],
    embedding=embeddings
)

# QA é“¾
llm = ChatOpenAI(
    api_key=settings.OPENAI_API_KEY,
    model=settings.OPENAI_MODEL
)

qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=vectorstore.as_retriever()
)

answer = qa_chain.run("é—®é¢˜")
```

## ğŸ”§ å¸¸è§é—®é¢˜

### Q1: å¯¼å…¥ settings æŠ¥é”™ï¼Ÿ
```python
# ç¡®ä¿ä»é¡¹ç›®æ ¹ç›®å½•å¯¼å…¥
from config import settings

# å¦‚æœè¿˜æ˜¯æŠ¥é”™ï¼Œæ£€æŸ¥ PYTHONPATH
import sys
sys.path.append('/path/to/agi_study')
```

### Q2: API Key ä¸ç”Ÿæ•ˆï¼Ÿ
```bash
# 1. ç¡®è®¤ .env æ–‡ä»¶åœ¨é¡¹ç›®æ ¹ç›®å½•
ls -la .env

# 2. ç¡®è®¤æ ¼å¼æ­£ç¡®ï¼ˆç­‰å·å‰åæ— ç©ºæ ¼ï¼‰
OPENAI_API_KEY=sk-xxx

# 3. é‡å¯ Python è§£é‡Šå™¨æˆ– PyCharm
```

### Q3: PyCharm ç»ˆç«¯ä¸æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼Ÿ
1. `Settings` â†’ `Tools` â†’ `Terminal`
2. å‹¾é€‰ `Activate virtualenv` æˆ– `Activate conda environment`
3. é‡å¯ç»ˆç«¯

### Q4: åŒ…å®‰è£…å¤±è´¥ï¼Ÿ
```bash
# ä½¿ç”¨å›½å†…é•œåƒ
pip install package-name -i https://mirrors.aliyun.com/pypi/simple/

# æˆ–ä¸´æ—¶ä¿¡ä»»
pip install package-name --trusted-host pypi.tuna.tsinghua.edu.cn
```

## ğŸ“š å­¦ä¹ è·¯å¾„

```
01-core-concepts/      â† ä»è¿™é‡Œå¼€å§‹
â”œâ”€â”€ prompt_engineering/
â”œâ”€â”€ function_calling/
â””â”€â”€ nlg/

02-frameworks/         â† ç„¶åå­¦æ¡†æ¶
â”œâ”€â”€ langchain/
â”œâ”€â”€ semantic_kernel/
â””â”€â”€ assistants_api/

03-ai-agent/          â† å†å­¦ Agent
â”œâ”€â”€ simple_agent/
â”œâ”€â”€ route_agent/
â””â”€â”€ cooperation_agent/

04-rag/               â† RAG åº”ç”¨
â”œâ”€â”€ base/
â”œâ”€â”€ chatpdf/
â””â”€â”€ graph_rag/

05-model-techniques/  â† é«˜çº§æŠ€æœ¯
â”œâ”€â”€ embedding/
â””â”€â”€ fine-tuning/

06-monitoring/        â† ç›‘æ§è¯„ä¼°
â””â”€â”€ langfuse/
```

## ğŸ¯ æœ€ä½³å®è·µ

### âœ… æ¨èåšæ³•

```python
# âœ… ä½¿ç”¨ç»Ÿä¸€é…ç½®
from config import settings
client = OpenAI(api_key=settings.OPENAI_API_KEY)

# âœ… ä½¿ç”¨ç±»å‹æç¤º
def process(text: str) -> str:
    return text.upper()

# âœ… ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨
with open('file.txt', 'r') as f:
    content = f.read()

# âœ… å¼‚å¸¸å¤„ç†
try:
    result = risky_operation()
except Exception as e:
    print(f"é”™è¯¯: {e}")
```

### âŒ é¿å…çš„åšæ³•

```python
# âŒ ç¡¬ç¼–ç å¯†é’¥
api_key = "sk-xxx"

# âŒ åˆ†æ•£é…ç½®
OPENAI_KEY = "xxx"  # åœ¨å¤šä¸ªæ–‡ä»¶ä¸­é‡å¤

# âŒ å¿½ç•¥å¼‚å¸¸
try:
    operation()
except:
    pass  # ä¸å¤„ç†ä¹Ÿä¸è®°å½•

# âŒ å…¨å±€å¯¼å…¥
from module import *  # ä¸æ¸…æ¥šå¯¼å…¥äº†ä»€ä¹ˆ
```

## ğŸ› ï¸ è°ƒè¯•æŠ€å·§

```python
# 1. æ‰“å°é…ç½®
from config import settings
settings.print_config()

# 2. å¯ç”¨ LangChain è°ƒè¯•
import langchain
langchain.debug = True

# 3. æŸ¥çœ‹æ¨¡å‹è¾“å‡º
response = llm.invoke("test")
print(response)  # æŸ¥çœ‹å®Œæ•´å“åº”å¯¹è±¡

# 4. ä½¿ç”¨ pdb è°ƒè¯•
import pdb; pdb.set_trace()
```

## ğŸ“ è·å–å¸®åŠ©

1. **æŸ¥çœ‹æ–‡æ¡£**ï¼š`CONFIG_USAGE.md`
2. **è¿è¡Œæµ‹è¯•**ï¼š`python config.py`
3. **æŸ¥çœ‹ç¤ºä¾‹**ï¼šå„ç›®å½•ä¸‹çš„ä»£ç æ–‡ä»¶
4. **æäº¤ Issue**ï¼šå¦‚æœé‡åˆ°é—®é¢˜

---

**è®°ä½**ï¼šæ‰€æœ‰é…ç½®éƒ½ç»Ÿä¸€åœ¨ `config.py`ï¼Œæ‰€æœ‰å¯†é’¥éƒ½æ”¾åœ¨ `.env` æ–‡ä»¶ä¸­ï¼

